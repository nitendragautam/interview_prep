package com.nitendratech.mapreduceapps.wordcount;

import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

/*
 * WordCount Reducer class 
 * 
 * reduce function collects all the intermediate key-value pairs  generated by the multiple map 
 * functions and will sum up all the occurrences of each word and output a key-value pair 
 * for each word in the text documents 
 */
public class WordCountReducer  extends Reducer<Text ,IntWritable ,Text ,IntWritable>{
	
	private IntWritable result = new IntWritable();
	
	
	//Acceps the Key/Value pairs from the mappers ,performs the aggregrations based on keys and produce the final output
	public void reduce(Text key ,Iterable<IntWritable> values ,Context context) throws IOException ,InterruptedException{
		int sumOfWordOccurence =0;
		//Iterates to every word
		for (IntWritable val :values ){
			sumOfWordOccurence += val.get();  //Counts and add the occurence of every word
		}
		result.set(sumOfWordOccurence);
		context.write(key, result); //Returning the key/Value pairs to Reducers which contains words and theri occurence number
	}

}
